{
  "test_date": "2025-10-23 23:13:45",
  "model_path": ".\\mlruns\\330612562760685645\\models\\m-e32c2072bfc742c1a9569c66b038fa48\\artifacts",
  "test_data_path": ".\\mlruns\\364772752496341707\\62c697a532b74b5fbc5fc06fb0403348\\artifacts\\processed_data\\test.csv",
  "total_samples": 11923,
  "processing_time_seconds": 1.3849875926971436,
  "samples_per_second": 8608.741379972213,
  "overall_accuracy": 0.8335989264446867,
  "correct_predictions": 1929,
  "incorrect_predictions": 1984,
  "avg_confidence": 0.5247258101167863,
  "std_confidence": 0.2131743833252668,
  "min_confidence": 0.18026733261731195,
  "max_confidence": 0.9997650703206764,
  "median_confidence": 0.4954119362949761,
  "anomaly_count": 9270,
  "anomaly_rate": 77.74888870250776,
  "avg_entropy": 1.9284594210010955,
  "class_statistics": [
    {
      "label": "age",
      "true_count": 1998,
      "pred_count": 2127,
      "correct": 1974,
      "precision": 0.9280677009873061,
      "recall": 0.987987987987988,
      "f1": 0.957090909090909,
      "avg_conf": 0.6320043689742865,
      "anomaly_rate": 63.01301301301301,
      "false_pos": 153,
      "false_neg": 24
    },
    {
      "label": "ethnicity",
      "true_count": 1990,
      "pred_count": 2023,
      "correct": 1943,
      "precision": 0.9604547701433515,
      "recall": 0.9763819095477387,
      "f1": 0.9683528532270123,
      "avg_conf": 0.6615530632348141,
      "anomaly_rate": 54.57286432160804,
      "false_pos": 80,
      "false_neg": 47
    },
    {
      "label": "gender",
      "true_count": 1993,
      "pred_count": 1899,
      "correct": 1716,
      "precision": 0.9036334913112164,
      "recall": 0.8610135474159558,
      "f1": 0.8818088386433709,
      "avg_conf": 0.5895998903958057,
      "anomaly_rate": 71.90165579528349,
      "false_pos": 183,
      "false_neg": 277
    },
    {
      "label": "not_cyberbullying",
      "true_count": 1986,
      "pred_count": 1637,
      "correct": 1043,
      "precision": 0.6371411117898595,
      "recall": 0.5251762336354482,
      "f1": 0.5757659398288711,
      "avg_conf": 0.3541061982822688,
      "anomaly_rate": 99.34541792547836,
      "false_pos": 594,
      "false_neg": 943
    },
    {
      "label": "other_cyberbullying",
      "true_count": 1956,
      "pred_count": 2175,
      "correct": 1334,
      "precision": 0.6133333333333333,
      "recall": 0.6820040899795501,
      "f1": 0.6458484628419269,
      "avg_conf": 0.3254176079118709,
      "anomaly_rate": 98.3640081799591,
      "false_pos": 841,
      "false_neg": 622
    },
    {
      "label": "religion",
      "true_count": 2000,
      "pred_count": 2062,
      "correct": 1929,
      "precision": 0.9354995150339476,
      "recall": 0.9645,
      "f1": 0.949778434268833,
      "avg_conf": 0.5657639954568768,
      "anomaly_rate": 79.75,
      "false_pos": 133,
      "false_neg": 71
    }
  ]
}